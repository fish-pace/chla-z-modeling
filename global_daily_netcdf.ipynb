{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe6c8b9-2581-4dde-9447-072103be47bd",
   "metadata": {},
   "source": [
    "# Create daily global netcdfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671dfdbf-2ba8-4a02-add7-46c39f07b1bb",
   "metadata": {},
   "source": [
    "## Step 1 a function to make a prediction from BRT\n",
    "\n",
    "This is in `ml_utils.py` but also bundled into a saved model. This outputs an xarray DataArray with time, z, lat, lon and our CHLA predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f580722-8af4-4052-9f30-25a6a3206294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "def predict_all_depths_for_day(\n",
    "    R: xr.DataArray,         # (lat, lon, wavelength)\n",
    "    brt_models: dict,        # e.g. {\"CHLA_0_10\": model0, \"CHLA_10_20\": model1, ...}\n",
    "    feature_cols: list,\n",
    "    consts=None,\n",
    "    chunk_size_lat: int = 100,\n",
    "    time=None,               # e.g. \"2024-07-15\" or np.datetime64\n",
    "    z: np.ndarray | None = None,   # optional override for depth centers\n",
    "    z_name: str = \"z\",       # vertical dimension name\n",
    "):\n",
    "    \"\"\"\n",
    "    Run BRT predictions for all depth bins for a single day.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    R : xr.DataArray\n",
    "        Predictor array of Rrs wavelengths from PACE on (lat, lon, wavelength) (no time dimension).\n",
    "    brt_models : dict\n",
    "        Mapping depth-label -> fitted model, e.g.\n",
    "        {\"CHLA_0_10\": model0, \"CHLA_10_20\": model1, ...}.\n",
    "        The last two underscore-separated tokens are assumed to be\n",
    "        depth start/end in meters, e.g. \"CHLA_0_10\" -> 0, 10.\n",
    "    feature_cols : list of str\n",
    "        Columns expected by the BRT models.\n",
    "    consts : dict, optional\n",
    "        Feature -> scalar value for constants (e.g. {\"solar_hour\": 12.0, \"type\": 1}).\n",
    "    chunk_size_lat : int\n",
    "        Number of latitude indices per chunk.\n",
    "    time : str or np.datetime64, optional\n",
    "        Time stamp for this prediction. If provided, a `time` dimension of length 1\n",
    "        is added to the output.\n",
    "    z : array-like, optional\n",
    "        Depth centers (same order as brt_models keys). If not given, centers are\n",
    "        inferred as (z_start + z_end)/2 from the model name.\n",
    "    z_name : str, default \"z\"\n",
    "        Name of the vertical dimension in the output.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        CHLA prediction with dims:\n",
    "            (time, z_name, lat, lon)      if `time` provided\n",
    "            (z_name, lat, lon)           otherwise\n",
    "\n",
    "        Coordinates:\n",
    "            z_name         : depth center (m)\n",
    "            f\"{z_name}_start\" : depth bin lower bound (m)\n",
    "            f\"{z_name}_end\"   : depth bin upper bound (m)\n",
    "    \"\"\"\n",
    "    consts = consts or {}\n",
    "    R = R.transpose(\"lat\", \"lon\", \"wavelength\")\n",
    "\n",
    "    depth_labels = list(brt_models.keys())\n",
    "    n_depth = len(depth_labels)\n",
    "\n",
    "    # --- parse z_start / z_end / z_center from labels like ABC_0_10 ---\n",
    "    z_start_arr = np.full(n_depth, np.nan, dtype=\"float32\")\n",
    "    z_end_arr   = np.full(n_depth, np.nan, dtype=\"float32\")\n",
    "    z_center_arr = np.full(n_depth, np.nan, dtype=\"float32\")\n",
    "\n",
    "    for i, label in enumerate(depth_labels):\n",
    "        parts = label.split(\"_\")\n",
    "        if len(parts) >= 3:\n",
    "            try:\n",
    "                z0 = float(parts[-2])\n",
    "                z1 = float(parts[-1])\n",
    "                z_start_arr[i] = z0\n",
    "                z_end_arr[i]   = z1\n",
    "                z_center_arr[i] = 0.5 * (z0 + z1)\n",
    "            except ValueError:\n",
    "                # leave as NaN if parsing fails\n",
    "                pass\n",
    "\n",
    "    # if user provided z, override centers\n",
    "    if z is not None:\n",
    "        z_center_arr = np.asarray(z, dtype=\"float32\")\n",
    "        if z_center_arr.shape[0] != n_depth:\n",
    "            raise ValueError(f\"len(z)={len(z_center_arr)} does not match number of models={n_depth}\")\n",
    "\n",
    "    nlat = R.sizes[\"lat\"]\n",
    "    lat_coord = R[\"lat\"]\n",
    "\n",
    "    depth_chunks = {label: [] for label in depth_labels}\n",
    "\n",
    "    # --- chunk over latitude ---\n",
    "    for start in range(0, nlat, chunk_size_lat):\n",
    "        stop = min(start + chunk_size_lat, nlat)\n",
    "        R_chunk = R.isel(lat=slice(start, stop))\n",
    "\n",
    "        for label, model in brt_models.items():\n",
    "            pred_chunk = make_prediction_brt(\n",
    "                R_chunk,\n",
    "                brt_model=model,\n",
    "                feature_cols=feature_cols,\n",
    "                solar_const=0, type_const=1,\n",
    "            )\n",
    "            depth_chunks[label].append(pred_chunk)\n",
    "\n",
    "    # --- stitch each depth over lat, then stack into vertical dimension ---\n",
    "    per_depth = []\n",
    "    for idx, (label, chunks) in enumerate(depth_chunks.items()):\n",
    "        da = xr.concat(chunks, dim=\"lat\").assign_coords(lat=lat_coord)\n",
    "        per_depth.append(da.expand_dims({z_name: [idx]}))\n",
    "\n",
    "    pred_all = xr.concat(per_depth, dim=z_name)  # (z, lat, lon)\n",
    "    pred_all.name = \"CHLA\"\n",
    "\n",
    "    # vertical coordinates\n",
    "    pred_all = pred_all.assign_coords(\n",
    "        {\n",
    "            z_name: z_center_arr,\n",
    "            f\"{z_name}_start\": (z_name, z_start_arr),\n",
    "            f\"{z_name}_end\":   (z_name, z_end_arr),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # optional time dimension\n",
    "    if time is not None:\n",
    "        time_val = np.datetime64(time)\n",
    "        pred_all = pred_all.expand_dims(time=[time_val])\n",
    "\n",
    "    # note about depth inference\n",
    "    pred_all.attrs.setdefault(\n",
    "        \"depth_info\",\n",
    "        f\"Depth coordinates inferred from brt_models keys of form 'NAME_z0_z1'. \"\n",
    "        f\"z is the bin center, {z_name}_start/{z_name}_end are bin bounds (m).\"\n",
    "    )\n",
    "\n",
    "    return pred_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b51f99-9948-4bb2-9f86-7635f0a8d6bb",
   "metadata": {},
   "source": [
    "## Create a dataset with our derived variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2892195-d70e-4f64-b730-a74a28941052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chla_profile_dataset(CHLA: xr.DataArray) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Given CHLA(time, z, lat, lon), compute derived metrics and\n",
    "    return an xr.Dataset suitable for writing to Zarr/NetCDF.\n",
    "    \"\"\"\n",
    "\n",
    "    z_thick = CHLA.coords.get(\"z_end\", None) - CHLA.coords.get(\"z_start\", None)\n",
    "    if z_thick is None or np.all(np.isnan(z_thick)):\n",
    "        # fallback: assume uniform 10 m bins, or something you know\n",
    "        z_thick = xr.full_like(CHLA.isel(z=0), 10.0)\n",
    "\n",
    "    # integrated CHLA 0â€“200m\n",
    "    CHLA_int = (CHLA * z_thick).sum(\"z\")\n",
    "    CHLA_int.name = \"CHLA_int_0_200\"\n",
    "\n",
    "    # peak value and depth\n",
    "    peak_idx = CHLA.argmax(\"z\")\n",
    "    CHLA_peak = CHLA.isel(z=peak_idx)\n",
    "    CHLA_peak.name = \"CHLA_peak\"\n",
    "\n",
    "    z_center = CHLA[\"z\"]\n",
    "    depth_peak = z_center.isel(z=peak_idx)\n",
    "    depth_peak.name = \"CHLA_peak_depth\"\n",
    "\n",
    "    # depth-weighted mean depth\n",
    "    num = (CHLA * z_center).sum(\"z\")\n",
    "    den = CHLA.sum(\"z\")\n",
    "    depth_cm = num / den\n",
    "    depth_cm.name = \"CHLA_depth_center_of_mass\"\n",
    "\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            \"CHLA\": CHLA,                     # (time, z, lat, lon)\n",
    "            \"CHLA_int_0_200\": CHLA_int,       # (time, lat, lon)\n",
    "            \"CHLA_peak\": CHLA_peak,           # (time, lat, lon)\n",
    "            \"CHLA_peak_depth\": depth_peak,    # (time, lat, lon)\n",
    "            \"CHLA_depth_center_of_mass\": depth_cm,  # (time, lat, lon)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # carry over coords and attrs from CHLA\n",
    "    ds = ds.assign_coords(CHLA.coords)\n",
    "    ds.attrs.update(CHLA.attrs)\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb26801-92bd-4587-aac8-07a32d7213c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## How long does a global prediciton take, 14 min\n",
    "\n",
    "R = rrs_ds[\"Rrs\"]\n",
    "feature_cols = list(X_train.columns)\n",
    "\n",
    "CHLA_day = predict_all_depths_for_day(\n",
    "    R=R,\n",
    "    brt_models=brt_models,\n",
    "    feature_cols=feature_cols,\n",
    "    consts={\"type\": 1, \"solar_hour\": 0},  \n",
    "    chunk_size_lat=100,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
